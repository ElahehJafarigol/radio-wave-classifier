{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hammification_network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHtI-kSVqZKY",
        "colab_type": "text"
      },
      "source": [
        "<h1>Deep Learning for Radio Waves</h1>\n",
        "<p>Radio signal classification methods have traditionally required expertly handcrafted feature extractors. It turns out that state of the art deep learning methods can be applied to the same problem of signal classification and shows excellent results while completely avoiding the need for difficult handcrafted feature selection.</p>\n",
        "<br>\n",
        "<p>This notebook describes one method of using deep learning for signal classification by turning classification into a similarity search problem. This model uses residual networks to extract signal embeddings from raw signal data. The signal embeddings are then converted into bit-vectors, or 'fingerprints', which can be used for similarity search.</p>\n",
        "<br>\n",
        "<p>This experiment is partly inspired by the following papers:</p>\n",
        "<a href=\"https://arxiv.org/pdf/1712.04578.pdf\">Over the Air Deep Learning Based Signal Classification</a>\n",
        "<br>\n",
        "<a href=\"https://arxiv.org/pdf/1706.03154.pdf\">Visual Search at Ebay</a>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAKOzvBHgn81",
        "colab_type": "code",
        "outputId": "d185a77c-6d25-42b6-96e6-136abb748c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import modules\n",
        "from IPython.display import display, clear_output\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print('S I G N A L   C L A S S I F I E R') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S I G N A L   C L A S S I F I E R\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwAft-yvqJdu",
        "colab_type": "text"
      },
      "source": [
        "<h1>Identify Signal Classes</h1>\n",
        "<p>The dataset has 24 different classes of signals:</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtFE8s7BgrTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import classes from .txt file \n",
        "classes = ['32PSK',\n",
        " '16APSK',\n",
        " '32QAM',\n",
        " 'FM',\n",
        " 'GMSK',\n",
        " '32APSK',\n",
        " 'OQPSK',\n",
        " '8ASK',\n",
        " 'BPSK',\n",
        " '8PSK',\n",
        " 'AM-SSB-SC',\n",
        " '4ASK',\n",
        " '16PSK',\n",
        " '64APSK',\n",
        " '128QAM',\n",
        " '128APSK',\n",
        " 'AM-DSB-SC',\n",
        " 'AM-SSB-WC',\n",
        " '64QAM',\n",
        " 'QPSK',\n",
        " '256QAM',\n",
        " 'AM-DSB-WC',\n",
        " 'OOK',\n",
        " '16QAM']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8BYEWhevDd2",
        "colab_type": "text"
      },
      "source": [
        "<h1>Loading the Data</h1>\n",
        "<p>The original dataset from Deepsig.io comes in .hdf5 format. I converted the data to .npy format since I found it took much less time to load. The signals are already divided into training, testing, and validation data. Here are links the dataset of labeled signals:</p>\n",
        "<a href=\"https://drive.google.com/file/d/1vrzz1Dbf98E-Q79-3CFjGNS7sw1HJVM6/view\">Dataset</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr44A7Gvgr3f",
        "colab_type": "code",
        "outputId": "55f61953-822c-4948-d80e-973387aa5632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "path = 'data/npy_data/signal_dataset/'\n",
        "\n",
        "# load training data\n",
        "print('Loading training data ...')\n",
        "x_train = np.load(path + 'train/signals.npy')\n",
        "y_train = np.load(path + 'train/labels.npy')\n",
        "snr_train = np.load(path + 'train/snrs.npy')\n",
        "print('Load complete!')\n",
        "print('\\n')\n",
        "\n",
        "# load validation data\n",
        "print('Loading validation data ...')\n",
        "x_val = np.load(path + 'validation/signals.npy')\n",
        "y_val = np.load(path + 'validation/labels.npy')\n",
        "snr_val = np.load(path + 'validation/snrs.npy')\n",
        "print('Load complete!')\n",
        "print('\\n')\n",
        "\n",
        "# load testing data\n",
        "print('Loading testing data ...')\n",
        "x_test = np.load(path + 'test/signals.npy')\n",
        "y_test = np.load(path + 'test/labels.npy')\n",
        "snr_test = np.load(path + 'test/snrs.npy')\n",
        "print('Load complete!')\n",
        "print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading training data ...\n",
            "Load complete!\n",
            "\n",
            "\n",
            "Loading validation data ...\n",
            "Load complete!\n",
            "\n",
            "\n",
            "Loading testing data ...\n",
            "Load complete!\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7ldgz-FvvRr",
        "colab_type": "text"
      },
      "source": [
        "<h1>Importing Keras: The Deep Learning Library for Python</h1>\n",
        "<p>Keras is a high-level neural networks API that is capable of running on top of Tensorflow as well as several other machine learning frameworks. Keras is developed with a focus on enabling fast-experimentation, simplifying the process of building neural networks and testing models.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixeNf-xIgt9i",
        "colab_type": "code",
        "outputId": "d86dfec8-be8b-42f2-cfb2-22ee899ade7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# import deep learning libraries\n",
        "import os\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.layers import Input, Dropout, Add, Dense, Reshape, Activation\n",
        "from keras.layers import BatchNormalization, Flatten, Conv1D, MaxPooling1D\n",
        "\n",
        "print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-n93BCiwxde",
        "colab_type": "text"
      },
      "source": [
        "<h1>The Model</h1>\n",
        "<p>This model is a residual neural network - it is a many-layered 1D convolutional neural network that uses a special layer called a 'skip connection' or 'shortcut connection' which essentially allows the model to learn more abstract features by avoiding the vanishing gradient problem.</p><br>\n",
        "<p1>On a more macro level, the model is constructed of 5 residual stacks (code shown below).</p1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdz5h9BYgw85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1d conv resnet\n",
        "def residual_stack(x, f):\n",
        "    # 1x1 conv linear\n",
        "    x = Conv1D(f, 1, strides=1, padding='same', data_format='channels_last')(x)\n",
        "    x = Activation('linear')(x)\n",
        "    \n",
        "    # residual unit 1    \n",
        "    x_shortcut = x\n",
        "    x = Conv1D(f, 3, strides=1, padding=\"same\", data_format='channels_last')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv1D(f, 3, strides=1, padding=\"same\", data_format='channels_last')(x)\n",
        "    x = Activation('linear')(x)\n",
        "    # add skip connection\n",
        "    if x.shape[1:] == x_shortcut.shape[1:]:\n",
        "      x = Add()([x, x_shortcut])\n",
        "    else:\n",
        "      raise Exception('Skip Connection Failure!')\n",
        "      \n",
        "    # residual unit 2    \n",
        "    x_shortcut = x\n",
        "    x = Conv1D(f, 3, strides=1, padding=\"same\", data_format='channels_last')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv1D(f, 3, strides = 1, padding = \"same\", data_format='channels_last')(x)\n",
        "    x = Activation('linear')(x)\n",
        "    # add skip connection\n",
        "    if x.shape[1:] == x_shortcut.shape[1:]:\n",
        "      x = Add()([x, x_shortcut])\n",
        "    else:\n",
        "      raise Exception('Skip Connection Failure!')\n",
        "      \n",
        "    # max pooling layer\n",
        "    x = MaxPooling1D(pool_size=2, strides=None, padding='valid', data_format='channels_last')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvh8ya-VyE5c",
        "colab_type": "text"
      },
      "source": [
        "<h1>Extracting Embeddings from the Network</h1>\n",
        "<p>The second to last layer will be the embedding layer of our network - A dense layer with a sigmoid activation that we will eventually use to extract signal embeddings and turn them into bit vectors of any desired length (say 100).</p>\n",
        "<h1>Why Bit Vectors?</h1>\n",
        "<p>Bit vectors are a convenient solution to similarity search since it is an efficient way of storing information about similarity. Instead of storing floating point signal data of shape (2, 1024), we can simply store it's bit-vector fingerprint of shape (100). This requires much less storage capacity</p><br>\n",
        "<p>Not only this, but bit vectors are compared using hamming distance, a much easier computation than direct euclidean distance</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJIx4gYHg22i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define resnet model\n",
        "def ResNet(input_shape, classes, bit_size):   \n",
        "    # create input tensor\n",
        "    x_input = Input(input_shape)\n",
        "    x = x_input\n",
        "    # residual stack\n",
        "    num_filters = 40\n",
        "    x = residual_stack(x, num_filters)\n",
        "    x = residual_stack(x, num_filters)\n",
        "    x = residual_stack(x, num_filters)\n",
        "    x = residual_stack(x, num_filters)\n",
        "    x = residual_stack(x, num_filters)\n",
        "    \n",
        "    # output layer\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation=\"selu\", kernel_initializer=\"he_normal\")(x)\n",
        "    x = Dropout(.5)(x)\n",
        "    x = Dense(128, activation=\"selu\", kernel_initializer=\"he_normal\")(x)\n",
        "    x = Dropout(.5)(x)\n",
        "    x = Dense(bit_size, activation=\"sigmoid\")(x)\n",
        "    x = Dense(classes , activation='softmax', kernel_initializer = glorot_uniform(seed=0))(x)\n",
        "    # Create model\n",
        "    model = Model(inputs = x_input, outputs = x)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3y1i-JthCQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# option to save model weights and model history\n",
        "save_model = True\n",
        "save_history = True\n",
        "\n",
        "# create directory for model weights\n",
        "if save_model is True:\n",
        "    weights_path = input(\"Name model weights directory: \")\n",
        "    weights_path = \"data/weights/\" + weights_path\n",
        "\n",
        "    try:\n",
        "        os.mkdir(weights_path)\n",
        "    except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % weights_path)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % weights_path)\n",
        "    print('\\n')\n",
        "    \n",
        "\n",
        "# create directory for model history\n",
        "if save_history is True:\n",
        "    history_path = input(\"Name model history directory: \")\n",
        "    history_path = \"data/model_history/\" + history_path\n",
        "\n",
        "    try:\n",
        "        os.mkdir(history_path)\n",
        "    except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % history_path)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % history_path)\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sSz0icNhDQC",
        "colab_type": "code",
        "outputId": "aa950185-39e3-4f42-d3ce-58d1f14c3523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# reshape input data\n",
        "x_train = x_train.reshape([-1, 1024, 2])\n",
        "x_val = x_val.reshape([-1, 1024, 2])\n",
        "x_test = x_test.reshape([-1, 1024, 2])\n",
        "\n",
        "# initialize optimizer \n",
        "adm = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "# set number of epochs\n",
        "num_epochs = input('Enter number of epochs: ')\n",
        "num_epochs = int(num_epochs)\n",
        "print('\\n')\n",
        "\n",
        "# set bit size\n",
        "bit_size = input('Enter bit size to learn: ')\n",
        "bit_size = int(bit_size)\n",
        "\n",
        "# set batch size\n",
        "batch = 32\n",
        "\n",
        "# configure weights save\n",
        "if save_model is True:\n",
        "    filepath= weights_path + \"/{epoch}.hdf5\"\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode=\"auto\")\n",
        "    callbacks_list = [checkpoint]\n",
        "else:\n",
        "    callbacks_list = []"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter number of epochs: 2\n",
            "\n",
            "\n",
            "Enter bit size to learn: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiZjmd5phHa0",
        "colab_type": "code",
        "outputId": "24f3fab5-45e5-4b3f-d5e5-51f4dbbb9c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initialize and train model\n",
        "model = ResNet((1024, 2), 24, bit_size)\n",
        "model.compile(optimizer=adm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit(x_train, y_train, epochs = num_epochs, batch_size=batch, callbacks=callbacks_list, validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0910 22:49:41.269590 140075799508736 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 1024, 2)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_26 (Conv1D)              (None, 1024, 40)     120         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 1024, 40)     0           conv1d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 1024, 40)     4840        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 1024, 40)     0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 1024, 40)     4840        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 1024, 40)     0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 1024, 40)     0           activation_28[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_29 (Conv1D)              (None, 1024, 40)     4840        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 1024, 40)     0           conv1d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_30 (Conv1D)              (None, 1024, 40)     4840        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 1024, 40)     0           conv1d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 1024, 40)     0           activation_30[0][0]              \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 512, 40)      0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_31 (Conv1D)              (None, 512, 40)      1640        max_pooling1d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 512, 40)      0           conv1d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_32 (Conv1D)              (None, 512, 40)      4840        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 512, 40)      0           conv1d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_33 (Conv1D)              (None, 512, 40)      4840        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 512, 40)      0           conv1d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 512, 40)      0           activation_33[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_34 (Conv1D)              (None, 512, 40)      4840        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 512, 40)      0           conv1d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_35 (Conv1D)              (None, 512, 40)      4840        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 512, 40)      0           conv1d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 512, 40)      0           activation_35[0][0]              \n",
            "                                                                 add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1D)  (None, 256, 40)      0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_36 (Conv1D)              (None, 256, 40)      1640        max_pooling1d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 256, 40)      0           conv1d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_37 (Conv1D)              (None, 256, 40)      4840        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 256, 40)      0           conv1d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_38 (Conv1D)              (None, 256, 40)      4840        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 256, 40)      0           conv1d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 256, 40)      0           activation_38[0][0]              \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_39 (Conv1D)              (None, 256, 40)      4840        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 256, 40)      0           conv1d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_40 (Conv1D)              (None, 256, 40)      4840        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 256, 40)      0           conv1d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 256, 40)      0           activation_40[0][0]              \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1D)  (None, 128, 40)      0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_41 (Conv1D)              (None, 128, 40)      1640        max_pooling1d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 128, 40)      0           conv1d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_42 (Conv1D)              (None, 128, 40)      4840        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 128, 40)      0           conv1d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_43 (Conv1D)              (None, 128, 40)      4840        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 128, 40)      0           conv1d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 128, 40)      0           activation_43[0][0]              \n",
            "                                                                 activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_44 (Conv1D)              (None, 128, 40)      4840        add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 128, 40)      0           conv1d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_45 (Conv1D)              (None, 128, 40)      4840        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 128, 40)      0           conv1d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 128, 40)      0           activation_45[0][0]              \n",
            "                                                                 add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1D)  (None, 64, 40)       0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_46 (Conv1D)              (None, 64, 40)       1640        max_pooling1d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 64, 40)       0           conv1d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_47 (Conv1D)              (None, 64, 40)       4840        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 64, 40)       0           conv1d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_48 (Conv1D)              (None, 64, 40)       4840        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 64, 40)       0           conv1d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 64, 40)       0           activation_48[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_49 (Conv1D)              (None, 64, 40)       4840        add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 64, 40)       0           conv1d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_50 (Conv1D)              (None, 64, 40)       4840        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 64, 40)       0           conv1d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 64, 40)       0           activation_50[0][0]              \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling1D) (None, 32, 40)       0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 1280)         0           max_pooling1d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          163968      flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 128)          16512       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 50)           6450        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 24)           1224        dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 291,634\n",
            "Trainable params: 291,634\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1022361 samples, validate on 127795 samples\n",
            "Epoch 1/2\n",
            "  95168/1022361 [=>............................] - ETA: 9:58 - loss: 2.8992 - acc: 0.1186"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c663d8ec8d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJMLl64ehKCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# record model history\n",
        "train_acc = history.history['acc']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "if save_history is True:\n",
        "    # save model history: loss and accuracy\n",
        "    np.save(history_path + '/train_acc.npy', train_acc)\n",
        "    np.save(history_path + '/train_loss.npy', train_loss)\n",
        "    np.save(history_path + '/val_acc.npy', val_acc)\n",
        "    np.save(history_path + '/val_loss.npy', val_loss)\n",
        "    print(\"Model History Saved!\")\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQbKCTlqhMZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate model on test data\n",
        "loss, acc = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print('EVALUATING MODEL ON TEST DATA:')\n",
        "print('Test Accuracy: ', str(round(acc*100, 2)), '%')\n",
        "print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}